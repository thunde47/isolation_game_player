
This script evaluates the performance of the custom_score evaluation
function against a baseline agent using alpha-beta search and iterative
deepening (ID) called `AB_Improved`. The three `AB_Custom` agents use
ID and alpha-beta search with the custom_score functions defined in
game_agent.py.

                        *************************                         
                             Playing Matches                              
                        *************************                         

 Match #   Opponent    AB_Improved   AB_Custom   AB_Custom_2  AB_Custom_3 
                        Won | Lost   Won | Lost   Won | Lost   Won | Lost 
    1       Random      48  |   2    42  |   8    43  |   7    48  |   2  
    2       MM_Open     25  |  25    31  |  19    30  |  20    35  |  15  
    3      MM_Center    35  |  15    35  |  15    37  |  13    44  |   6  
    4     MM_Improved   21  |  29    27  |  23    29  |  21    37  |  13  
    5       AB_Open     27  |  23    22  |  28    24  |  26    29  |  21  
    6      AB_Center    21  |  29    28  |  22    29  |  21    34  |  16  
    7     AB_Improved   23  |  27    32  |  18    28  |  22    37  |  13  
--------------------------------------------------------------------------
           Win Rate:      57.1%        62.0%        62.9%        75.4%    


There were 1.0 timeouts during the tournament -- make sure your agent handles search timeout correctly, and consider increasing the timeout margin for your agent.


Your ID search forfeited 57.0 games while there were still legal moves available to play.

